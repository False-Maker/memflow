## 原因定位（结合你反馈“测试连接/问答都正常”）
- 这条 `OpenAI 调用超时，使用回退解析` 是 **智能搜索的意图解析**专用逻辑触发的：它对 LLM 调用额外包了一层 **8 秒超时**，超过就直接回退解析。
- 你的“测试连接 OK、问答 OK”说明：
  - Key / Base URL / 网络整体是通的；
  - 但 **OpenAI/网关在某些时刻响应 > 8 秒**，只有意图解析会因此被判定为“超时”，问答和测试连接通常允许更长时间（没有这层 8 秒限制或体验上不明显）。

## 计划（改动很小，目标：不再误判为超时，同时保留回退能力）
### 1) 提高意图解析超时，并做“分级回退”
- 把 `parse_query_intent` 的超时从 8s 调整到更合理的值（建议 20s）。
- 仍保留回退解析：只有真正超时/失败才回退。

### 2) 让超时可配置（可选但推荐）
- 在 AppConfig 增加一个可选字段（例如 `intentParseTimeoutMs`），默认 20000。
- 设置页可不露出该项（先用默认），或者加到高级设置里。

### 3) 增加“超时诊断日志”（不含任何敏感信息）
- 超时时额外记录：使用的 `base_url`、`model_id`、超时时长（都不含 key），方便区分“偶发慢”还是“某个网关特定路径慢”。

### 4) 验证
- 跑 `pnpm test`（已有相关单测）+ 启动 dev，连续点 10 次智能搜索确认不再频繁回退。

如果你确认，我就按以上步骤提交补丁。