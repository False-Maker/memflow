## 为什么你一问就总有“可优化点”
- **优化点 ≠ 没检查全**：很多条目不是“缺陷/会坏”，而是“可以更稳/更快/更好维护”。只要项目在演进，这类点永远存在。
- **每次检查的“目标范围”不同**：前文我们主要围绕你要的优化链路（search total、去重、向量候选集、配置一致性、测试回归）做了验证；这类验证能证明“改动正确且不回归”，但不等于把项目所有维度（性能、极端输入、安全、打包体验、长期运行）都拉满。
- **很多问题只有在“更深一层的检查方法”才会出现**：
  - 例如编译告警（unused/dead_code）属于“工程洁癖/维护性”，不会让功能坏，但可以进一步收敛。
  - 例如 FTS 的特殊字符输入、DB vacuum/索引、embedding 存储格式，是“规模化/长时间运行”才更关键。

## 以后想“检查更全”，我建议固定用这套覆盖清单（每轮都可复用）

### 1) 静态质量（最容易漏，但也最便宜）
- Rust：`cargo test` 之外，要求 **0 warnings**（unused/dead_code 等）
- 前端：`pnpm lint` + `pnpm type-check`
- 规则：出现 warning 先分类（必须修/可延后），避免每次复盘都重复出现

### 2) 功能回归（你已经做得比较到位）
- 关键命令：录制、搜索（含 rank）、OCR 更新事件、配置读写
- 最小集成：启动一次 `tauri:dev`，走一遍核心路径（不做长时间测试也能排 80% 的错）

### 3) 边界/异常输入（最容易“线上才暴雷”）
- FTS/MATCH：包含引号、括号、特殊符号的 query
- 网络/AI：key 缺失、超时、流式中断、空响应
- OCR：服务启动失败/端口占用/模型缺失

### 4) 性能与资源（需要专门测，日常很容易“没测到”）
- DB：索引覆盖、COUNT 查询成本、retention 后文件体积回收
- 向量：embedding 解码成本、候选集规模对延迟的影响
- 长时间运行：内存增长、队列堆积

### 5) 交付体验（打包/安装/依赖）
- OCR 是否可“安装即用”
- 权限/路径/杀软影响（Windows 常见）

## 我建议的沟通方式（避免你觉得我“每次都检查不全”）
- 以后我会把输出明确分两类：
  1) **缺陷/回归风险（必须修）**：不修会坏、会报错、会影响用户数据。
  2) **增强/优化建议（可选）**：不修不影响正确性，但能提升性能/维护性。
- 并且每轮都给出“本轮覆盖了哪些维度、哪些没覆盖”，让“没查到”变成“明确没在本轮范围”。

## 如果你确认，我下一轮会怎么做（只做‘检查更全’，不强行加需求）
1. 先输出一份“当前仓库检查清单结果”报告：静态告警、边界输入、性能热点、打包风险各一条摘要。
2. 再按优先级给你一个短 list：必须修 1-3 个 + 可选 3-5 个（都附具体文件位置）。
3. 你点头后再进入实施阶段（逐项修复 + 测试验证）。