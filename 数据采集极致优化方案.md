## 目标与约束
- **目标**：降低采集主循环抖动（p99 周期）、降低 CPU/内存峰值、减少磁盘与 SQLite 写放大、让 OCR 处理端到端延迟更低且可控。
- **约束**：不牺牲核心体验（截图回看、文本可搜索）；隐私模式/黑白名单逻辑保持一致；任何“激进策略”必须可配置/可回退。

## 当前链路概览（你认同的两点所处位置）
- **采集主链路**：[recorder.rs]：窗口信息 → UIA 文本尝试 → 截图+WebP → 写库 activity_logs → 文本补全（UIA 成功直接写；UIA 失败走 OCR）。
- **OCR 处理**：[ocr_worker.rs] + [db.rs ocr_queue]：从队列取任务 → 调 RapidOCR → 更新 activity_logs.ocr_text → emit 前端事件。

## 优化点 1（你认同点 A）：OCR 队列化 + 背压（Backpressure）
**目标**：把“昂贵且不确定时延”的 OCR 从采集热路径剥离，避免主循环被 OCR 拖慢；同时能控制并发，避免 CPU/内存打满。
- **策略**
  - 采集侧（recorder）：UIA 失败时只做 `enqueue_ocr_task(activity_id)`，不做任何 OCR 运算。
  - 处理侧（worker）：按并发上限（Semaphore）并行跑 OCR，失败重试、超限标记 failed。
- **落地点**
  - [recorder.rs]：仅入队，不跑 OCR。
  - [db.rs] / migrations：`ocr_queue(activity_id unique, status, retry_count, updated_at)`。
  - [ocr_worker.rs]：并发处理 + 状态更新 + 事件回推。
- **关键配置建议**
  - `ocr_worker_concurrency`（默认 2，可按机器能力调整）
  - `ocr_worker_fetch_limit`（默认 10）
  - `ocr_max_retries`（默认 3）

## 优化点 2（你认同点 B）：采集热路径去阻塞（UIA/截图/编码/落盘）
**目标**：主循环只做编排，不在 Tokio runtime 上执行任何重 CPU 或阻塞 IO。
- **策略**
  - UIA 提取：放到 `spawn_blocking`（COM/UIA 调用属于阻塞/系统调用密集型）。
  - 截图 + pHash + WebP 编码：统一放到 `spawn_blocking`。
  - 文件写入：用 `tokio::fs::write`（异步 IO），避免阻塞。
- **落地点**
  - [recorder.rs]：将 UIA 与截图编码拆成两个 blocking 段 + async 写盘。
- **收益指标**
  - 采集函数 `capture_and_save` 的 p95/p99 `total_ms` 显著下降，且方差变小。

## 优化点 3（你认同点 C）：OCR worker 并发与批处理
**目标**：OCR 积压时吞吐更高；空闲时不浪费资源。
- **策略**
  - `Semaphore` 控制 OCR 并发（避免打爆 CPU/内存）。
  - 每次被触发后尽量 **drain 队列**：批量取任务 → 并发跑 → 再取 → 直到空。
- **落地点**
  - [ocr_worker.rs]：JoinSet + Semaphore + drain loop。

## 新增优化点 4：OCR 入队即唤醒（Notify），消除轮询延迟
**目标**：端到端 OCR 延迟不再受 5s 轮询影响，UIA 失败后几乎立刻开始 OCR。
- **策略**
  - 在 worker 内部维护 `Notify`：`select! { ticker | notify }`。
  - 入队成功后立即 `notify_one()`。
- **落地点**
  - [ocr_worker.rs]：`static Notify` + `notify_new_task()`。
  - [recorder.rs]：enqueue 成功后调用 notify。
- **收益指标**
  - “UIA 失败 → OCR 开始处理”的延迟从 0~5s 变为 ~0ms（仅调度延迟）。

## 新增优化点 5：OCR 前图像预处理（强推荐优先做）
**目标**：对全景/高分辨率截图显著降低 OCR 成本（文件读写、上传、推理耗时）。
- **策略（worker 侧做，风险最小）**
  - 解码 WebP → **等比例缩放到固定宽度**（例如 1280 或 1600）→ 重新编码为 PNG/JPEG（或直接把缩放后内存图送到 OCR，若 OCR API 支持 bytes）。
  - 可选：对疑似纯背景/低信息图做快速跳过（基于边缘密度/对比度阈值）。
- **配置建议**
  - `ocr_preprocess_enabled`（默认 true）
  - `ocr_target_width`（默认 1280）
  - `ocr_max_pixels`（超过则缩放）
- **验证方式**
  - 对比 OCR 文本长度、关键词召回（抽样人工验证）与耗时（ocr_ms）。

## 新增优化点 6：自适应采样频率（降低长期资源占用）
**目标**：静态阅读场景减少无意义采集；交互密集时保持足够采样。
- **策略**
  - 结合：窗口切换事件、标题变化（可选）、键鼠活跃度（已有 focus_analytics）
  - 动态调整心跳间隔：例如 10s~60s 范围内自适应。
- **落地点**
  - [recorder.rs]：heartbeat 逻辑从固定上限改为“自适应计算”。
- **风险与控制**
  - 必须保留一个最大间隔兜底，避免漏录。

## 新增优化点 7：多屏全景拼接的拷贝/内存峰值优化
**目标**：多显示器、高分辨率时降低峰值内存与 CPU 拷贝。
- **策略**
  - 减少 `pixels().flat_map().collect()` 这种逐像素 push 的分配方式，改为更接近“行拷贝/批量填充”。
  - 尽可能复用缓冲区（如果 xcap 输出格式允许）。
- **落地点**
  - [recorder.rs capture_screen]：多屏分支。

## 新增优化点 8：DB 写放大与锁竞争再压一层
**目标**：降低“每条活动 insert + 后续 update”的写锁竞争与 WAL 压力。
- **策略**
  - OCR 更新时合并：如果短时间内同 activity_id 多次更新，仅保留最后一次。
  - 将部分统计（skipped_stat）做内存聚合后批量落库（例如每 10s flush）。
  - 视情况添加索引/优化查询（保持写入不被索引拖慢）。

## 可观测性（必须做，才能把优化做到极致）
- **采集链路**：在 [recorder.rs] 打点输出 `uia_ms/capture_ms/write_ms/db_ms/total_ms`，并统计分位数（可先用日志聚合，后续可加专门 metrics 表）。
- **OCR 链路**：在 [ocr_worker.rs] 打点 `ocr_ms/db_ms`，并在 DB 中暴露队列统计接口（pending/processing/done/failed）。
- **SLO 建议**
  - capture_and_save：p95 < 150ms（单屏典型），p99 < 300ms（视机器）
  - OCR：入队到开始处理 p95 < 50ms；队列 pending 稳态接近 0

## 验证与回归测试
- 单测：保持现有 `cargo test` 全过。
- 压测：新增一个 `#[ignore]` 的本地压测用例（pHash/WebP/OCR 预处理分别压），用 `--ignored --nocapture` 输出耗时。
- 端到端：实际运行 30min，检查
  - 采集是否漏帧（事件驱动 + 心跳兜底）
  - OCR 是否持续回填
  - DB 是否出现锁等待/错误

## 实施顺序（收益/风险比从高到低）
1. OCR 入队即唤醒（Notify） + drain 队列（立竿见影降延迟）
2. OCR 前缩放预处理（最显著降 OCR 成本）
3. 自适应采样频率（长期资源占用最值）
4. 多屏拼接拷贝优化（特定用户收益大）
5. DB 写放大进一步合并（需要更谨慎验证）

## 回退方案
- 所有新增策略都挂到 config 开关（预处理/自适应/合并写入），出现问题可一键关闭回退到当前稳定策略。

如果你确认，我会按上述顺序把 2/3/Notify 这一组 + OCR 缩放预处理先完整做完，并补齐配置项与验证脚本。